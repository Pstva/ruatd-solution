{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03269ac1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T16:48:15.355373Z",
     "iopub.status.busy": "2022-03-01T16:48:15.353764Z",
     "iopub.status.idle": "2022-03-01T16:48:27.010608Z",
     "shell.execute_reply": "2022-03-01T16:48:27.009847Z",
     "shell.execute_reply.started": "2022-03-01T16:06:21.999585Z"
    },
    "executionInfo": {
     "elapsed": 9821,
     "status": "ok",
     "timestamp": 1645821766618,
     "user": {
      "displayName": "Алена Пестова",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17998310572331852810"
     },
     "user_tz": -180
    },
    "id": "r4XSMbu2V8do",
    "papermill": {
     "duration": 11.710959,
     "end_time": "2022-03-01T16:48:27.010798",
     "exception": false,
     "start_time": "2022-03-01T16:48:15.299839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qq transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eaf6511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T16:48:27.066415Z",
     "iopub.status.busy": "2022-03-01T16:48:27.065612Z",
     "iopub.status.idle": "2022-03-01T16:48:34.841907Z",
     "shell.execute_reply": "2022-03-01T16:48:34.841281Z",
     "shell.execute_reply.started": "2022-03-01T16:06:29.223217Z"
    },
    "executionInfo": {
     "elapsed": 5542,
     "status": "ok",
     "timestamp": 1645821772151,
     "user": {
      "displayName": "Алена Пестова",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17998310572331852810"
     },
     "user_tz": -180
    },
    "id": "762ZRqILV9oB",
    "papermill": {
     "duration": 7.805896,
     "end_time": "2022-03-01T16:48:34.842105",
     "exception": false,
     "start_time": "2022-03-01T16:48:27.036209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import  BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f366374a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T16:48:34.891772Z",
     "iopub.status.busy": "2022-03-01T16:48:34.890615Z",
     "iopub.status.idle": "2022-03-01T16:48:34.892919Z",
     "shell.execute_reply": "2022-03-01T16:48:34.893578Z",
     "shell.execute_reply.started": "2022-03-01T16:06:37.436544Z"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1645821774269,
     "user": {
      "displayName": "Алена Пестова",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17998310572331852810"
     },
     "user_tz": -180
    },
    "id": "IVkUtMsdWblI",
    "papermill": {
     "duration": 0.029662,
     "end_time": "2022-03-01T16:48:34.893749",
     "exception": false,
     "start_time": "2022-03-01T16:48:34.864087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "MAX_LEN = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a241b",
   "metadata": {
    "id": "xzWyJQEEV4ez",
    "papermill": {
     "duration": 0.021105,
     "end_time": "2022-03-01T16:48:34.937158",
     "exception": false,
     "start_time": "2022-03-01T16:48:34.916053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1675ae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T16:48:34.989930Z",
     "iopub.status.busy": "2022-03-01T16:48:34.989152Z",
     "iopub.status.idle": "2022-03-01T16:48:36.603886Z",
     "shell.execute_reply": "2022-03-01T16:48:36.602983Z",
     "shell.execute_reply.started": "2022-03-01T16:06:39.569392Z"
    },
    "executionInfo": {
     "elapsed": 1169,
     "status": "ok",
     "timestamp": 1645821775414,
     "user": {
      "displayName": "Алена Пестова",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17998310572331852810"
     },
     "user_tz": -180
    },
    "id": "SFXAYOeSU-rZ",
    "papermill": {
     "duration": 1.644774,
     "end_time": "2022-03-01T16:48:36.604063",
     "exception": false,
     "start_time": "2022-03-01T16:48:34.959289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = 'data/'\n",
    "\n",
    "label2idx= {'M':1, 'М':1, 'H':0, 'Н':0}\n",
    "data = pd.read_csv(PATH +'train.csv')\n",
    "data['Class'] = data['Class'].replace(label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96b0cb34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T16:48:36.654928Z",
     "iopub.status.busy": "2022-03-01T16:48:36.653868Z",
     "iopub.status.idle": "2022-03-01T16:48:42.867620Z",
     "shell.execute_reply": "2022-03-01T16:48:42.867016Z",
     "shell.execute_reply.started": "2022-03-01T16:06:43.559279Z"
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1645821775825,
     "user": {
      "displayName": "Алена Пестова",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17998310572331852810"
     },
     "user_tz": -180
    },
    "id": "cT9NyFjqU-t2",
    "papermill": {
     "duration": 6.241604,
     "end_time": "2022-03-01T16:48:42.867816",
     "exception": false,
     "start_time": "2022-03-01T16:48:36.626212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527b7fd21a684a0a959ceec3d1869697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbd38ab6ab740a5b3a1dbfab60dab4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1226125e6ce42c89fb7aecf7f654e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f3ec7fe7be49eabef8ae551f22634e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b66d6d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T16:48:42.930023Z",
     "iopub.status.busy": "2022-03-01T16:48:42.929066Z",
     "iopub.status.idle": "2022-03-01T16:48:42.933288Z",
     "shell.execute_reply": "2022-03-01T16:48:42.932700Z",
     "shell.execute_reply.started": "2022-03-01T16:06:48.467293Z"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1645821776102,
     "user": {
      "displayName": "Алена Пестова",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17998310572331852810"
     },
     "user_tz": -180
    },
    "id": "fwttBE1qU-wH",
    "papermill": {
     "duration": 0.037774,
     "end_time": "2022-03-01T16:48:42.933448",
     "exception": false,
     "start_time": "2022-03-01T16:48:42.895674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "\n",
    "  def __init__(self, texts, targets, tokenizer, max_len):\n",
    "    self.texts = texts\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.texts)\n",
    "  \n",
    "  def __getitem__(self, item):\n",
    "    text = str(self.texts[item])\n",
    "    #H=0, M=1\n",
    "    target = self.targets[item]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      text,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding='max_length',\n",
    "      truncation=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    return {\n",
    "      'text': text,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'segment_ids' : torch.tensor([0] * self.max_len, dtype=torch.long),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7c87242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T16:48:42.990889Z",
     "iopub.status.busy": "2022-03-01T16:48:42.989850Z",
     "iopub.status.idle": "2022-03-01T16:48:43.113274Z",
     "shell.execute_reply": "2022-03-01T16:48:43.112066Z",
     "shell.execute_reply.started": "2022-03-01T16:06:51.325885Z"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1645821776102,
     "user": {
      "displayName": "Алена Пестова",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17998310572331852810"
     },
     "user_tz": -180
    },
    "id": "BgDRcYhuYUa2",
    "papermill": {
     "duration": 0.154906,
     "end_time": "2022-03-01T16:48:43.113424",
     "exception": false,
     "start_time": "2022-03-01T16:48:42.958518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df_train, df_val = train_test_split(data, test_size=0.1, random_state=RANDOM_SEED, stratify=data['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49730202",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T16:48:43.170760Z",
     "iopub.status.busy": "2022-03-01T16:48:43.169533Z",
     "iopub.status.idle": "2022-03-01T16:48:43.171890Z",
     "shell.execute_reply": "2022-03-01T16:48:43.172653Z",
     "shell.execute_reply.started": "2022-03-01T16:06:53.162278Z"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1645821776103,
     "user": {
      "displayName": "Алена Пестова",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17998310572331852810"
     },
     "user_tz": -180
    },
    "id": "U0O1aicZYUd3",
    "papermill": {
     "duration": 0.034559,
     "end_time": "2022-03-01T16:48:43.172824",
     "exception": false,
     "start_time": "2022-03-01T16:48:43.138265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = TextDataset(\n",
    "    texts=df.Text.to_numpy(),\n",
    "    targets=df.Class.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=2\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5becbcf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T16:48:43.243896Z",
     "iopub.status.busy": "2022-03-01T16:48:43.242856Z",
     "iopub.status.idle": "2022-03-01T16:48:43.245621Z",
     "shell.execute_reply": "2022-03-01T16:48:43.246157Z",
     "shell.execute_reply.started": "2022-03-01T16:06:56.392686Z"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1645821776104,
     "user": {
      "displayName": "Алена Пестова",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17998310572331852810"
     },
     "user_tz": -180
    },
    "id": "chW3QMOgYwWL",
    "papermill": {
     "duration": 0.034755,
     "end_time": "2022-03-01T16:48:43.246331",
     "exception": false,
     "start_time": "2022-03-01T16:48:43.211576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a913f8ec",
   "metadata": {
    "papermill": {
     "duration": 0.024475,
     "end_time": "2022-03-01T16:48:43.295051",
     "exception": false,
     "start_time": "2022-03-01T16:48:43.270576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Функции для обуения и оценки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9af7eba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T16:48:43.356283Z",
     "iopub.status.busy": "2022-03-01T16:48:43.355147Z",
     "iopub.status.idle": "2022-03-01T16:48:43.357460Z",
     "shell.execute_reply": "2022-03-01T16:48:43.358054Z",
     "shell.execute_reply.started": "2022-03-01T16:06:57.795456Z"
    },
    "papermill": {
     "duration": 0.038902,
     "end_time": "2022-03-01T16:48:43.358261",
     "exception": false,
     "start_time": "2022-03-01T16:48:43.319359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    predicted_labels, correct_labels = [], []\n",
    "\n",
    "    model.to(device)\n",
    "    for step, batch in enumerate(tqdm(dataloader, desc=\"Evaluation iteration\")):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        label_ids = batch[\"targets\"].to(device)\n",
    "        segment_ids = batch['segment_ids'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids, attention_mask=attention_mask,\n",
    "                               labels=label_ids, token_type_ids=segment_ids)\n",
    "        tmp_eval_loss, logits = output[0], output[1]\n",
    "\n",
    "        outputs = np.argmax(logits.to('cpu'), axis=1)\n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "        \n",
    "        predicted_labels += list(outputs)\n",
    "        correct_labels += list(label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    \n",
    "    correct_labels = np.array(correct_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "        \n",
    "    return eval_loss, correct_labels, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3293abdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T16:48:43.432874Z",
     "iopub.status.busy": "2022-03-01T16:48:43.416783Z",
     "iopub.status.idle": "2022-03-01T16:48:43.436093Z",
     "shell.execute_reply": "2022-03-01T16:48:43.435512Z",
     "shell.execute_reply.started": "2022-03-01T16:07:10.354414Z"
    },
    "papermill": {
     "duration": 0.053641,
     "end_time": "2022-03-01T16:48:43.436271",
     "exception": false,
     "start_time": "2022-03-01T16:48:43.382630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, dev_dataloader, output_model_file,\n",
    "          num_train_epochs=10, patience=2, gradient_accumulation_steps=1, max_grad_norm=5,\n",
    "          warmup_proportion=0.1, batch_size=8, learning_rate=5e-5): \n",
    "    \n",
    "    num_train_steps = int(len(df_train) / batch_size / gradient_accumulation_steps * num_train_epochs)\n",
    "    num_warmup_steps = int(warmup_proportion * num_train_steps)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, correct_bias=False)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, \n",
    "                                                num_training_steps=num_train_steps)\n",
    "    \n",
    "    train_losses, dev_losses = [],[]\n",
    "    \n",
    "    train_accuracies, train_f1_scores, dev_accuracies, dev_f1_scores = [], [], [], []\n",
    "    no_improvement = 0\n",
    "    for _ in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
    "        train_predictions = []\n",
    "        train_labels = []\n",
    "        model.train()\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training iteration\")):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            label_ids = batch[\"targets\"].to(device)\n",
    "            segment_ids = batch['segment_ids'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=label_ids,\n",
    "                           token_type_ids=segment_ids)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            train_predictions += list(np.argmax(logits.detach().to('cpu'), axis=1))\n",
    "            train_labels += list(batch[\"targets\"].to('cpu').numpy())\n",
    "\n",
    "            if gradient_accumulation_steps > 1:\n",
    "                loss = loss / gradient_accumulation_steps\n",
    "\n",
    "            loss.backward()\n",
    "            tr_loss += loss.mean().item()\n",
    "\n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) \n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad() \n",
    "                scheduler.step()\n",
    "                \n",
    "            nb_tr_steps += 1\n",
    "                \n",
    "        tr_loss /= nb_tr_steps\n",
    "        train_accuracies.append(accuracy_score(train_labels, train_predictions))\n",
    "        train_f1_scores.append(f1_score(train_labels, train_predictions, average='macro'))\n",
    "        \n",
    "        dev_loss, correct_labels, predicted_labels = evaluate(model, dev_dataloader, device=\"cuda\")\n",
    "        dev_accuracies.append(accuracy_score(correct_labels, predicted_labels))\n",
    "        dev_f1_scores.append(f1_score(correct_labels, predicted_labels, average='macro'))\n",
    "        \n",
    "        print(\"Train loss:\", tr_loss, 'Train acc: ', train_accuracies[-1], \"Train_f1: \", train_f1_scores[-1])\n",
    "        print(\"Dev loss:\", dev_loss, 'Dev acc: ', dev_accuracies[-1], \"Dev_f1: \", dev_f1_scores[-1])\n",
    "\n",
    "        if len(dev_losses) == 0 or dev_accuracies[-1] > min(dev_accuracies):\n",
    "            no_improvement = 0\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model\n",
    "            torch.save(model_to_save.state_dict(), output_model_file)\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "        \n",
    "        if no_improvement >= patience:\n",
    "            print(\"No improvement on development set. Finish training.\")\n",
    "            break\n",
    "\n",
    "        dev_losses.append(dev_loss)\n",
    "        train_losses.append(tr_loss)\n",
    "        \n",
    "    return train_losses, dev_losses, train_accuracies, train_f1_scores, dev_accuracies, dev_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f986f267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T16:48:43.495584Z",
     "iopub.status.busy": "2022-03-01T16:48:43.494707Z",
     "iopub.status.idle": "2022-03-01T16:49:08.870593Z",
     "shell.execute_reply": "2022-03-01T16:49:08.869632Z",
     "shell.execute_reply.started": "2022-03-01T16:07:12.018494Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 25.410024,
     "end_time": "2022-03-01T16:49:08.870755",
     "exception": false,
     "start_time": "2022-03-01T16:48:43.460731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b8a5fc12d848de889d206d7d56c449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2label = {1:'M', 0:'H'}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME, num_labels = len(idx2label))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5ebbb4",
   "metadata": {
    "papermill": {
     "duration": 0.028374,
     "end_time": "2022-03-01T16:49:08.927893",
     "exception": false,
     "start_time": "2022-03-01T16:49:08.899519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Обучение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2de7d295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T16:49:08.995233Z",
     "iopub.status.busy": "2022-03-01T16:49:08.994186Z",
     "iopub.status.idle": "2022-03-01T16:15:29.587459Z",
     "shell.execute_reply": "2022-03-01T16:15:29.586456Z",
     "shell.execute_reply.started": "2022-03-01T16:07:22.579317Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2022-03-01T16:49:08.958327",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f43ae7015f24c2a948bf0505778ee7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/9680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7241417e9f04e7a904b2d5c5e79f71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/1076 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.13706728214944505 Train acc:  0.6704258817655111 Train_f1:  0.6703091197669191\n",
      "Dev loss: 0.5219017489359724 Dev acc:  0.683737506779267 Dev_f1:  0.6645748678656168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|█         | 1/10 [1:49:38<16:26:50, 6578.97s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059686f11a6141c8b5bf6b31883710c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/9680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb6b0ab2bcc462ab8974d82e04085d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/1076 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.12405942486606784 Train acc:  0.7158808185332174 Train_f1:  0.7158234795019094\n",
      "Dev loss: 0.49755632269393557 Dev acc:  0.7120167351049818 Dev_f1:  0.7028079306732792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 2/10 [3:39:15<14:36:58, 6577.35s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e64f06748b4f3298b95a34c26de836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/9680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1cd4481b6d4d198b4e3ac557ab550a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/1076 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.11615004600641464 Train acc:  0.739305606969757 Train_f1:  0.7392560743686794\n",
      "Dev loss: 0.4879895089519622 Dev acc:  0.7260401332610211 Dev_f1:  0.7192379607566612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|███       | 3/10 [5:28:51<12:47:18, 6576.99s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255b25d770404b4b87317a45086b1071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/9680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c524f167a343fc9d42673c4cc3d71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/1076 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1079448224383037 Train acc:  0.7640819910639727 Train_f1:  0.76405718690267\n",
      "Dev loss: 0.49913804921006516 Dev acc:  0.7337103897110095 Dev_f1:  0.7301234808466088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 4/10 [7:18:29<10:57:42, 6577.14s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824bfc156e6647b79c7d25dbecd74c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/9680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95a89732ed8451bb97ebc2d49e9c0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/1076 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0986014811679998 Train acc:  0.7898570063447516 Train_f1:  0.7898370823889493\n",
      "Dev loss: 0.5249665773864904 Dev acc:  0.7378941659564577 Dev_f1:  0.7371031207081657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 5/10 [9:08:09<9:08:11, 6578.36s/it] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f6f774592845a78a293bc81001fcca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/9680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd4311c55c9492587646ba78914ae45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/1076 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.08900040994472379 Train acc:  0.8153909727184291 Train_f1:  0.815379416774865\n",
      "Dev loss: 0.5948227841621715 Dev acc:  0.7362671418610056 Dev_f1:  0.7342841700394438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 6/10 [10:57:51<7:18:38, 6579.71s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78795374f4d3448e84e959147d4792be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/9680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OUTPUT_FILE=PATH + \"models/bert.bin\",\n",
    "EPOCHS=10\n",
    "\n",
    "train_losses, dev_losses,  train_accuracies, train_f1_scores, dev_accuracies, dev_f1_scores = train(model, \n",
    "                                                                                       train_data_loader, val_data_loader, \n",
    "                                                                                       gradient_accumulation_steps=4, batch_size=BATCH_SIZE,\n",
    "                                                                                        output_model_file = OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac70d366",
   "metadata": {},
   "source": [
    "### Метрики на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee6292",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = {1:'M', 0:'H'}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME, num_labels = len(idx2label))\n",
    "model.load_state_dict(torch.load('models/bert.bin'))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "PATH = 'data/'\n",
    "\n",
    "label2idx= {'M':1, 'М':1, 'H':0, 'Н':0}\n",
    "data = pd.read_csv(PATH +'val.csv')\n",
    "data['Class'] = data['Class'].replace(label2idx)\n",
    "BATCH_SIZE=12\n",
    "\n",
    "test_data_loader = create_data_loader(data, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "eval_loss, correct_labels, predicted_labels = evaluate(model, test_data_loader, device='cuda')\n",
    "print(classification_report(correct_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a9de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#              precision    recall  f1-score   support\n",
    "#\n",
    "#           0       0.70      0.82      0.76     10756\n",
    "#           1       0.78      0.65      0.71     10755\n",
    "#\n",
    "#    accuracy                           0.74     21511\n",
    "#   macro avg       0.74      0.74      0.73     21511\n",
    "#weighted avg       0.74      0.74      0.73     21511"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a52734",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b0c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_proba_predictions(model, dataloader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    \n",
    "    predicted_proba, predicted_labels = [], []\n",
    "\n",
    "    model.to(device)\n",
    "    for step, batch in enumerate(tqdm(dataloader, desc=\"Evaluation iteration\")):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        segment_ids = batch['segment_ids'].to(device)\n",
    "        label_ids = batch[\"targets\"].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids, attention_mask=attention_mask,\n",
    "                               labels=label_ids, token_type_ids=segment_ids)\n",
    "        logits = output[1]\n",
    "\n",
    "        outputs = np.argmax(logits.to('cpu'), axis=1)\n",
    "        predicted_labels += list(outputs)\n",
    "        predicted_proba += list(logits.to('cpu').numpy())\n",
    "        \n",
    "\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "        \n",
    "    return predicted_proba, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd47af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.read_csv('data/test.csv')\n",
    "subm['Class'] = 0\n",
    "sumb_data_loader = create_data_loader(subm, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "_, predicted_labels = make_proba_predictions(model, sumb_data_loader, device='cuda')\n",
    "\n",
    "subm['Class'] = predicted_labels\n",
    "subm['Class'] = subm['Class'].replace(idx2label)\n",
    "subm[['Id', 'Class']].to_csv('submissions/submission_bert_5_512.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-01T16:48:05.102206",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
